{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce43ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Starting analysis with Google gemini-2.0-flash-exp\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Analysis Configuration:\n",
      "   Total questions: 60\n",
      "   Questions with images: 60\n",
      "   Questions without images: 0\n",
      "   Repetitions: 1\n",
      "   Delay between requests: 4.0s\n",
      "\n",
      "â±ï¸  Estimated Time:\n",
      "   Total API calls: 120\n",
      "   Minimum time (with delays): 8.0 minutes (0.1 hours)\n",
      "\n",
      "ðŸ’¡ Tip: Reduce DELAY_BETWEEN_REQUESTS if you have higher rate limits\n",
      "======================================================================\n",
      "\n",
      "\n",
      "######################################################################\n",
      "### STARTING REPETITION 1 with gemini-2.0-flash-exp ###\n",
      "### Rate limiting: 4.0s delay between requests ###\n",
      "######################################################################\n",
      "\n",
      "[Rep 1] Loaded image for IT0006\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0006\n",
      "[Rep 1] IT0006: Correct=C, Real=Bâœ—, Fake=Dâœ—\n",
      "[Rep 1] Loaded image for IT0007\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0007\n",
      "[Rep 1] IT0007: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0031\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0031\n",
      "[Rep 1] IT0031: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0032\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0032\n",
      "[Rep 1] IT0032: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0053\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0053\n",
      "[Rep 1] IT0053: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0054\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0054\n",
      "[Rep 1] IT0054: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0063\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0063\n",
      "[Rep 1] IT0063: Correct=C, Real=Eâœ—, Fake=Eâœ—\n",
      "[Rep 1] Loaded image for IT0064\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0064\n",
      "[Rep 1] IT0064: Correct=D, Real=Dâœ“, Fake=Dâœ“\n",
      "[Rep 1] Loaded image for IT0065\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0065\n",
      "[Rep 1] IT0065: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0095\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0095\n",
      "[Rep 1] IT0095: Correct=C, Real=Dâœ—, Fake=Aâœ—\n",
      "[Rep 1] Loaded image for IT0111\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0111\n",
      "[Rep 1] IT0111: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0130\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0130\n",
      "[Rep 1] IT0130: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0131\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0131\n",
      "[Rep 1] IT0131: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0136\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0136\n",
      "[Rep 1] IT0136: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0169\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0169\n",
      "[Rep 1] IT0169: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0198\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0198\n",
      "[Rep 1] IT0198: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0200\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0200\n",
      "[Rep 1] IT0200: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0213\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0213\n",
      "[Rep 1] IT0213: Correct=B, Real=Bâœ“, Fake=Eâœ—\n",
      "[Rep 1] Loaded image for IT0214\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0214\n",
      "[Rep 1] IT0214: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0229\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0229\n",
      "[Rep 1] IT0229: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0235\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0235\n",
      "[Rep 1] IT0235: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0236\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0236\n",
      "[Rep 1] IT0236: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0250\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0250\n",
      "[Rep 1] IT0250: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0311\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0311\n",
      "[Rep 1] IT0311: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT0340\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0340\n",
      "[Rep 1] IT0340: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0375\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0375\n",
      "[Rep 1] IT0375: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0390\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0390\n",
      "[Rep 1] IT0390: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0455\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0455\n",
      "[Rep 1] IT0455: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0456\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0456\n",
      "[Rep 1] IT0456: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0507\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0507\n",
      "[Rep 1] IT0507: Correct=A, Real=Bâœ—, Fake=Bâœ—\n",
      "[Rep 1] Loaded image for IT0512\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0512\n",
      "[Rep 1] IT0512: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0532\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0532\n",
      "[Rep 1] IT0532: Correct=C, Real=Câœ“, Fake=Eâœ—\n",
      "[Rep 1] Loaded image for IT0533\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0533\n",
      "[Rep 1] IT0533: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0563\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0563\n",
      "[Rep 1] IT0563: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT0593\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0593\n",
      "[Rep 1] IT0593: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0597\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0597\n",
      "[Rep 1] IT0597: Correct=D, Real=Dâœ“, Fake=Dâœ“\n",
      "[Rep 1] Loaded image for IT0653\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0653\n",
      "[Rep 1] IT0653: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0675\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0675\n",
      "[Rep 1] IT0675: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0676\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0676\n",
      "[Rep 1] IT0676: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0713\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0713\n",
      "[Rep 1] IT0713: Correct=C, Real=Aâœ—, Fake=Aâœ—\n",
      "[Rep 1] Loaded image for IT0783\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0783\n",
      "[Rep 1] IT0783: Correct=D, Real=Dâœ“, Fake=Dâœ“\n",
      "[Rep 1] Loaded image for IT0784\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0784\n",
      "[Rep 1] IT0784: Correct=A, Real=Dâœ—, Fake=Dâœ—\n",
      "[Rep 1] Loaded image for IT0785\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0785\n",
      "[Rep 1] IT0785: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT0860\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0860\n",
      "[Rep 1] IT0860: Correct=B, Real=Bâœ“, Fake=Bâœ“\n",
      "[Rep 1] Loaded image for IT0861\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0861\n",
      "[Rep 1] IT0861: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0890\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0890\n",
      "[Rep 1] IT0890: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT0891\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0891\n",
      "[Rep 1] IT0891: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT0892\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0892\n",
      "[Rep 1] IT0892: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT0908\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0908\n",
      "[Rep 1] IT0908: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT0919\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0919\n",
      "[Rep 1] IT0919: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT0949\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0949\n",
      "[Rep 1] IT0949: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT0972\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT0972\n",
      "[Rep 1] IT0972: Correct=E, Real=Eâœ“, Fake=Eâœ“\n",
      "[Rep 1] Loaded image for IT1022\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT1022\n",
      "[Rep 1] IT1022: Correct=D, Real=Dâœ“, Fake=Dâœ“\n",
      "[Rep 1] Loaded image for IT1023\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT1023\n",
      "[Rep 1] IT1023: Correct=A, Real=Aâœ“, Fake=Aâœ“\n",
      "[Rep 1] Loaded image for IT1044\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT1044\n",
      "[Rep 1] IT1044: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT1053\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT1053\n",
      "[Rep 1] IT1053: Correct=C, Real=Câœ“, Fake=Câœ“\n",
      "[Rep 1] Loaded image for IT1100\n",
      "\n",
      "[Rep 1] Processing question with IMAGE: IT1100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 494\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# Run multiple repetitions\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_REPETITIONS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 494\u001b[0m     results, skipped \u001b[38;5;241m=\u001b[39m process_single_repetition(\n\u001b[0;32m    495\u001b[0m         df, worksheet, picture_link_col, FAKE_IMAGE_PATH, rep\n\u001b[0;32m    496\u001b[0m     )\n\u001b[0;32m    497\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mextend(results)\n\u001b[0;32m    498\u001b[0m     all_skipped\u001b[38;5;241m.\u001b[39mextend(skipped)\n",
      "Cell \u001b[1;32mIn[16], line 309\u001b[0m, in \u001b[0;36mprocess_single_repetition\u001b[1;34m(df, worksheet, picture_link_col, fake_image_path, repetition_num)\u001b[0m\n\u001b[0;32m    299\u001b[0m content_fake\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     }\n\u001b[0;32m    306\u001b[0m })\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# Call Gemini with fake image and reasoning\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m response_fake \u001b[38;5;241m=\u001b[39m call_gemini_with_image(content_fake, use_reasoning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response_fake:\n\u001b[0;32m    312\u001b[0m     claude_answer_fake \u001b[38;5;241m=\u001b[39m parse_claude_response(response_fake)\n",
      "Cell \u001b[1;32mIn[16], line 128\u001b[0m, in \u001b[0;36mcall_gemini_with_image\u001b[1;34m(content, use_reasoning)\u001b[0m\n\u001b[0;32m    125\u001b[0m         img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(BytesIO(image_data))\n\u001b[0;32m    126\u001b[0m         prompt_parts\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m--> 128\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt_parts)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Add delay after API call to respect rate limits\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DELAY_BETWEEN_REQUESTS \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    836\u001b[0m     request,\n\u001b[0;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    840\u001b[0m )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    293\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    295\u001b[0m     target,\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    297\u001b[0m     sleep_generator,\n\u001b[0;32m    298\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    299\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    300\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:75\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\grpc\\_interceptor.py:276\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    269\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 276\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_call(\n\u001b[0;32m    277\u001b[0m         request,\n\u001b[0;32m    278\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    279\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    280\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    281\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mwait_for_ready,\n\u001b[0;32m    282\u001b[0m         compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\grpc\\_interceptor.py:328\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 328\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[0;32m    329\u001b[0m     continuation, client_call_details, request\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:79\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[1;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[0;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m         },\n\u001b[0;32m     77\u001b[0m     )\n\u001b[1;32m---> 79\u001b[0m response \u001b[38;5;241m=\u001b[39m continuation(client_call_details, request)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\grpc\\_interceptor.py:314\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[1;34m(new_details, request)\u001b[0m\n\u001b[0;32m    305\u001b[0m (\n\u001b[0;32m    306\u001b[0m     new_method,\n\u001b[0;32m    307\u001b[0m     new_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m     new_compression,\n\u001b[0;32m    312\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thunk(new_method)\u001b[38;5;241m.\u001b[39mwith_call(\n\u001b[0;32m    315\u001b[0m         request,\n\u001b[0;32m    316\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mnew_timeout,\n\u001b[0;32m    317\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mnew_metadata,\n\u001b[0;32m    318\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mnew_credentials,\n\u001b[0;32m    319\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mnew_wait_for_ready,\n\u001b[0;32m    320\u001b[0m         compression\u001b[38;5;241m=\u001b[39mnew_compression,\n\u001b[0;32m    321\u001b[0m     )\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:1177\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_call\u001b[39m(\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1170\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[1;32m-> 1177\u001b[0m     state, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1178\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1179\u001b[0m     )\n\u001b[0;32m   1180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\zilef\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:1150\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1133\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1134\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1135\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1149\u001b[0m )\n\u001b[1;32m-> 1150\u001b[0m event \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m   1151\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config import GOOGLE_API_KEY  # Make sure this is in your config.py\n",
    "import openpyxl\n",
    "import requests\n",
    "import io \n",
    "from io import BytesIO\n",
    "import base64\n",
    "import sys\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time  # For rate limiting\n",
    "\n",
    "# Initialize Gemini client\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"Please set GOOGLE_API_KEY in config.py\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Model configuration - CHANGE THIS to use different Gemini models\n",
    "MODEL_NAME = \"gemini-2.0-flash-exp\"  # Options: \"gemini-2.0-flash-exp\", \"gemini-1.5-pro\", \"gemini-pro-vision\"\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "# ==== RATE LIMITING CONFIGURATION ====\n",
    "# Gemini rate limits (as of 2025):\n",
    "# - Free tier: 15 requests per minute (RPM)\n",
    "# - Pay-as-you-go: 360 RPM for Flash, 60 RPM for Pro\n",
    "# Adjust DELAY_BETWEEN_REQUESTS based on your tier and needs\n",
    "\n",
    "DELAY_BETWEEN_REQUESTS = 4.0  # seconds between API calls\n",
    "\n",
    "# Recommended delays for different tiers:\n",
    "# Free tier (15 RPM): 4.0 seconds (safe margin)\n",
    "# Basic tier (60 RPM): 1.0 seconds\n",
    "# Standard tier (360 RPM): 0.2 seconds\n",
    "# No limit needed: 0.0 seconds\n",
    "\n",
    "# For questions with images, there are 2 API calls (real + fake image)\n",
    "# So effective delay per question = DELAY_BETWEEN_REQUESTS * 2\n",
    "\n",
    "# System prompts\n",
    "SYSTEM_PROMPT = \"\"\"You must reply with NO explanations, NO headers, NO extra text.\n",
    "Language: ENGLISH. Keep the output strictly in the required format.\n",
    "\n",
    "You will receive ONE medical question with:\n",
    "- Text fields: QuestionID, Question, options A..E (some may be null).\n",
    "- Optionally ONE image immediately after the text (when provided).\n",
    "\n",
    "Task: choose EXACTLY ONE correct option among A, B, C, D, E for the QuestionID.\n",
    "You may consider the image when present.\n",
    "\n",
    "STRICT output format:\n",
    "QuestionID, LETTER\n",
    "\n",
    "Example:\n",
    "ES3341, B\n",
    "\n",
    "RULES:\n",
    "- Output EXACTLY ONE line in the exact format above.\n",
    "- Do NOT repeat the instructions.\n",
    "- Do NOT include the option text, ONLY the letter.\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_WITH_REASONING = \"\"\"You will receive ONE medical question with:\n",
    "- Text fields: QuestionID, Question, options A..E (some may be null).\n",
    "- Optionally ONE image immediately after the text (when provided).\n",
    "\n",
    "Task: \n",
    "1. Choose EXACTLY ONE correct option among A, B, C, D, E for the QuestionID.\n",
    "2. Provide your reasoning for selecting this answer.\n",
    "\n",
    "Output format:\n",
    "QuestionID, LETTER\n",
    "Reasoning: [Your detailed reasoning here]\n",
    "\n",
    "Example:\n",
    "ES3341, B\n",
    "Reasoning: The image shows characteristic signs of...\"\"\"\n",
    "\n",
    "USER_LEAD = \"Below is a single record. Use ONLY the relevant information.\"\n",
    "\n",
    "def build_content_like_main_script(question_id: str, question_text: str, options: dict) -> list:\n",
    "    \"\"\"Build content in the same format as the main script\"\"\"\n",
    "    content = []\n",
    "    \n",
    "    # Start with the lead text\n",
    "    lines = [USER_LEAD, f\"QuestionID: {question_id}\"]\n",
    "    \n",
    "    # Add question text\n",
    "    if question_text:\n",
    "        lines.append(f\"Question: {question_text}\")\n",
    "    \n",
    "    # Add options A through E\n",
    "    for label in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "        option_text = options.get(label, \"\")\n",
    "        lines.append(f\"{label}) {option_text if option_text else ''}\")\n",
    "    \n",
    "    # Create text content block\n",
    "    content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"\\n\".join(lines)\n",
    "    })\n",
    "    \n",
    "    return content\n",
    "\n",
    "def call_gemini_with_image(content, use_reasoning=False):\n",
    "    \"\"\"Call Gemini API and return parsed response\"\"\"\n",
    "    try:\n",
    "        # Build prompt parts for Gemini\n",
    "        prompt_parts = []\n",
    "        \n",
    "        # Add system prompt\n",
    "        prompt_parts.append(SYSTEM_PROMPT_WITH_REASONING if use_reasoning else SYSTEM_PROMPT)\n",
    "        prompt_parts.append(\"\\n\\n\")\n",
    "        \n",
    "        # Add content\n",
    "        for item in content:\n",
    "            if item[\"type\"] == \"text\":\n",
    "                prompt_parts.append(item[\"text\"])\n",
    "            elif item[\"type\"] == \"image\":\n",
    "                # Decode base64 image for Gemini\n",
    "                image_data = base64.b64decode(item['source']['data'])\n",
    "                img = Image.open(BytesIO(image_data))\n",
    "                prompt_parts.append(img)\n",
    "        \n",
    "        response = model.generate_content(prompt_parts)\n",
    "        \n",
    "        # Add delay after API call to respect rate limits\n",
    "        if DELAY_BETWEEN_REQUESTS > 0:\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "        \n",
    "        return response.text.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {e}\")\n",
    "        \n",
    "        # If rate limit error, wait longer and return None\n",
    "        if \"429\" in str(e) or \"quota\" in str(e).lower() or \"rate limit\" in str(e).lower():\n",
    "            print(f\"Rate limit hit! Waiting {DELAY_BETWEEN_REQUESTS * 3} seconds...\")\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS * 3)\n",
    "        \n",
    "        return None\n",
    "\n",
    "def parse_claude_response(text):\n",
    "    \"\"\"Parse model's response to extract answer letter\"\"\"\n",
    "    import re\n",
    "    LINE_RX = re.compile(r'^\\s*([^,]+)\\s*,\\s*([A-Ea-e])\\s*$', re.UNICODE)\n",
    "    \n",
    "    if text:\n",
    "        first_line = text.splitlines()[0] if text else \"\"\n",
    "        m = LINE_RX.match(first_line)\n",
    "        if m:\n",
    "            qid_out = m.group(1).strip()\n",
    "            letter = m.group(2).upper().strip()\n",
    "            return letter\n",
    "        else:\n",
    "            return \"PARSE_ERROR\"\n",
    "    else:\n",
    "        return \"NO_RESPONSE\"\n",
    "\n",
    "def process_single_repetition(df, worksheet, picture_link_col, fake_image_path, repetition_num):\n",
    "    \"\"\"Process all questions for one repetition\"\"\"\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"### STARTING REPETITION {repetition_num} with {MODEL_NAME} ###\")\n",
    "    print(f\"### Rate limiting: {DELAY_BETWEEN_REQUESTS}s delay between requests ###\")\n",
    "    print(f\"{'#'*70}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    skipped_questions = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        question_id = row['questionID']\n",
    "        question_text = row['question_text']\n",
    "        correct_answer = row['correct_option']\n",
    "        excel_row = index + 2\n",
    "        \n",
    "        # Check if picture_link column exists and get its value\n",
    "        picture_link = row.get('picture_link', 'N/A')\n",
    "        has_image = False\n",
    "        real_image = None\n",
    "        \n",
    "        # Try to load real image if available\n",
    "        if picture_link != 'N/A' and pd.notna(picture_link):\n",
    "            cell = worksheet.cell(row=excel_row, column=picture_link_col)\n",
    "            if cell.hyperlink and cell.hyperlink.target:\n",
    "                try:\n",
    "                    url = cell.hyperlink.target\n",
    "                    file_id = url.split(\"/d/\")[1].split(\"/\")[0]\n",
    "                    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "                    response = requests.get(download_url, timeout=30)\n",
    "                    img = Image.open(BytesIO(response.content))\n",
    "                    \n",
    "                    # Convert RGBA to RGB\n",
    "                    if img.mode in ('RGBA', 'LA'):\n",
    "                        background = Image.new('RGB', img.size, (255, 255, 255))\n",
    "                        background.paste(img, mask=img.split()[-1])\n",
    "                        img = background\n",
    "                    \n",
    "                    real_image = img\n",
    "                    has_image = True\n",
    "                    print(f\"[Rep {repetition_num}] Loaded image for {question_id}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[Rep {repetition_num}] Failed to load image for {question_id}: {e}\")\n",
    "        \n",
    "        # Skip questions with invalid correct_option\n",
    "        if pd.isna(correct_answer) or correct_answer is None:\n",
    "            print(f\"[Rep {repetition_num}] Skipping {question_id}: correct_option is NaN/None\")\n",
    "            skipped_questions.append({\n",
    "                \"repetition\": repetition_num,\n",
    "                \"question_id\": question_id,\n",
    "                \"reason\": \"correct_option is NaN/None\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Convert to string and handle blanks\n",
    "        correct_answer_str = str(correct_answer).strip().upper()\n",
    "\n",
    "        if not correct_answer_str or correct_answer_str not in ['A', 'B', 'C', 'D', 'E']:\n",
    "            print(f\"[Rep {repetition_num}] Skipping {question_id}: Invalid correct_option '{correct_answer}'\")\n",
    "            skipped_questions.append({\n",
    "                \"repetition\": repetition_num,\n",
    "                \"question_id\": question_id,\n",
    "                \"reason\": f\"Invalid correct_option: {correct_answer}\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Build options dictionary\n",
    "        options = {\n",
    "            \"A\": row['option_a'],\n",
    "            \"B\": row['option_b'], \n",
    "            \"C\": row['option_c'],\n",
    "            \"D\": row['option_d'],\n",
    "            \"E\": row['option_e']\n",
    "        }\n",
    "        \n",
    "        # Initialize result dictionary\n",
    "        result = {\n",
    "            \"repetition\": repetition_num,\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question_text,\n",
    "            \"correct_answer\": correct_answer.upper(),\n",
    "            \"has_image\": has_image\n",
    "        }\n",
    "        \n",
    "        # If question has image, process with both real and fake images\n",
    "        if has_image and real_image is not None:\n",
    "            print(f\"\\n[Rep {repetition_num}] Processing question with IMAGE: {question_id}\")\n",
    "            \n",
    "            # Build base content\n",
    "            content_base = build_content_like_main_script(question_id, question_text, options)\n",
    "            \n",
    "            # ==== REAL IMAGE ====\n",
    "            content_real = content_base.copy()\n",
    "            \n",
    "            # Add real image\n",
    "            buffer = BytesIO()\n",
    "            real_image.save(buffer, format='JPEG')\n",
    "            image_data_real = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "            \n",
    "            content_real.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/jpeg\",\n",
    "                    \"data\": image_data_real\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # Call Gemini with real image and reasoning\n",
    "            response_real = call_gemini_with_image(content_real, use_reasoning=True)\n",
    "            \n",
    "            if response_real:\n",
    "                claude_answer_real = parse_claude_response(response_real)\n",
    "                result[\"claude_answer_real\"] = claude_answer_real\n",
    "                result[\"claude_response_real\"] = response_real\n",
    "                result[\"is_correct_real\"] = (correct_answer.upper() == claude_answer_real)\n",
    "            else:\n",
    "                result[\"claude_answer_real\"] = \"API_ERROR\"\n",
    "                result[\"claude_response_real\"] = \"API_ERROR\"\n",
    "                result[\"is_correct_real\"] = False\n",
    "            \n",
    "            # ==== FAKE IMAGE ====\n",
    "            content_fake = content_base.copy()\n",
    "            \n",
    "            # Load and add fake image\n",
    "            try:\n",
    "                fake_img = Image.open(fake_image_path)\n",
    "                if fake_img.mode in ('RGBA', 'LA'):\n",
    "                    background = Image.new('RGB', fake_img.size, (255, 255, 255))\n",
    "                    background.paste(fake_img, mask=fake_img.split()[-1])\n",
    "                    fake_img = background\n",
    "                \n",
    "                buffer_fake = BytesIO()\n",
    "                fake_img.save(buffer_fake, format='JPEG')\n",
    "                image_data_fake = base64.b64encode(buffer_fake.getvalue()).decode('utf-8')\n",
    "                \n",
    "                content_fake.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/jpeg\",\n",
    "                        \"data\": image_data_fake\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                # Call Gemini with fake image and reasoning\n",
    "                response_fake = call_gemini_with_image(content_fake, use_reasoning=True)\n",
    "                \n",
    "                if response_fake:\n",
    "                    claude_answer_fake = parse_claude_response(response_fake)\n",
    "                    result[\"claude_answer_fake\"] = claude_answer_fake\n",
    "                    result[\"claude_response_fake\"] = response_fake\n",
    "                    result[\"is_correct_fake\"] = (correct_answer.upper() == claude_answer_fake)\n",
    "                else:\n",
    "                    result[\"claude_answer_fake\"] = \"API_ERROR\"\n",
    "                    result[\"claude_response_fake\"] = \"API_ERROR\"\n",
    "                    result[\"is_correct_fake\"] = False\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[Rep {repetition_num}] Error loading fake image: {e}\")\n",
    "                result[\"claude_answer_fake\"] = \"FAKE_IMAGE_ERROR\"\n",
    "                result[\"claude_response_fake\"] = f\"Error: {e}\"\n",
    "                result[\"is_correct_fake\"] = False\n",
    "            \n",
    "            print(f\"[Rep {repetition_num}] {question_id}: Correct={correct_answer.upper()}, \"\n",
    "                  f\"Real={result.get('claude_answer_real', 'N/A')}{'âœ“' if result.get('is_correct_real', False) else 'âœ—'}, \"\n",
    "                  f\"Fake={result.get('claude_answer_fake', 'N/A')}{'âœ“' if result.get('is_correct_fake', False) else 'âœ—'}\")\n",
    "            \n",
    "        else:\n",
    "            # No image - process normally\n",
    "            print(f\"[Rep {repetition_num}] Processing question WITHOUT image: {question_id}\")\n",
    "            content = build_content_like_main_script(question_id, question_text, options)\n",
    "            \n",
    "            response_text = call_gemini_with_image(content, use_reasoning=False)\n",
    "            \n",
    "            if response_text:\n",
    "                claude_answer = parse_claude_response(response_text)\n",
    "                result[\"claude_answer\"] = claude_answer\n",
    "                result[\"is_correct\"] = (correct_answer.upper() == claude_answer)\n",
    "            else:\n",
    "                result[\"claude_answer\"] = \"API_ERROR\"\n",
    "                result[\"is_correct\"] = False\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return results, skipped_questions\n",
    "\n",
    "def compute_aggregated_statistics(all_results):\n",
    "    \"\"\"Compute aggregated statistics with confidence intervals\"\"\"\n",
    "    \n",
    "    # Group results by question_id\n",
    "    question_results = defaultdict(lambda: {\n",
    "        'correct_answer': None,\n",
    "        'has_image': False,\n",
    "        'real_correct': [],\n",
    "        'fake_correct': [],\n",
    "        'no_image_correct': []\n",
    "    })\n",
    "    \n",
    "    for result in all_results:\n",
    "        qid = result['question_id']\n",
    "        question_results[qid]['correct_answer'] = result['correct_answer']\n",
    "        question_results[qid]['has_image'] = result.get('has_image', False)\n",
    "        \n",
    "        if result.get('has_image', False):\n",
    "            question_results[qid]['real_correct'].append(result.get('is_correct_real', False))\n",
    "            question_results[qid]['fake_correct'].append(result.get('is_correct_fake', False))\n",
    "        else:\n",
    "            question_results[qid]['no_image_correct'].append(result.get('is_correct', False))\n",
    "    \n",
    "    # Calculate statistics for each question\n",
    "    aggregated = []\n",
    "    \n",
    "    for qid, data in question_results.items():\n",
    "        correct = data['correct_answer']\n",
    "        \n",
    "        if data['has_image']:\n",
    "            real_correct = data['real_correct']\n",
    "            fake_correct = data['fake_correct']\n",
    "            n = len(real_correct)\n",
    "            \n",
    "            real_correct_count = sum(real_correct)\n",
    "            fake_correct_count = sum(fake_correct)\n",
    "            \n",
    "            real_accuracy = real_correct_count / n if n > 0 else 0\n",
    "            fake_accuracy = fake_correct_count / n if n > 0 else 0\n",
    "            \n",
    "            # Wilson score confidence interval (95%)\n",
    "            from scipy import stats\n",
    "            if n > 0:\n",
    "                real_ci = stats.binom.interval(0.95, n, real_accuracy) if real_accuracy > 0 else (0, 0)\n",
    "                fake_ci = stats.binom.interval(0.95, n, fake_accuracy) if fake_accuracy > 0 else (0, 0)\n",
    "                real_ci_lower = real_ci[0] / n\n",
    "                real_ci_upper = real_ci[1] / n\n",
    "                fake_ci_lower = fake_ci[0] / n\n",
    "                fake_ci_upper = fake_ci[1] / n\n",
    "            else:\n",
    "                real_ci_lower = real_ci_upper = 0\n",
    "                fake_ci_lower = fake_ci_upper = 0\n",
    "            \n",
    "            aggregated.append({\n",
    "                'question_id': qid,\n",
    "                'correct_answer': correct,\n",
    "                'has_image': True,\n",
    "                'num_repetitions': n,\n",
    "                # Real image stats\n",
    "                'real_correct_count': real_correct_count,\n",
    "                'real_accuracy': real_accuracy,\n",
    "                'real_ci_lower': real_ci_lower,\n",
    "                'real_ci_upper': real_ci_upper,\n",
    "                # Fake image stats\n",
    "                'fake_correct_count': fake_correct_count,\n",
    "                'fake_accuracy': fake_accuracy,\n",
    "                'fake_ci_lower': fake_ci_lower,\n",
    "                'fake_ci_upper': fake_ci_upper\n",
    "            })\n",
    "        else:\n",
    "            no_image_correct = data['no_image_correct']\n",
    "            n = len(no_image_correct)\n",
    "            correct_count = sum(no_image_correct)\n",
    "            accuracy = correct_count / n if n > 0 else 0\n",
    "            \n",
    "            # Wilson score confidence interval (95%)\n",
    "            from scipy import stats\n",
    "            if n > 0:\n",
    "                ci = stats.binom.interval(0.95, n, accuracy) if accuracy > 0 else (0, 0)\n",
    "                ci_lower = ci[0] / n\n",
    "                ci_upper = ci[1] / n\n",
    "            else:\n",
    "                ci_lower = ci_upper = 0\n",
    "            \n",
    "            aggregated.append({\n",
    "                'question_id': qid,\n",
    "                'correct_answer': correct,\n",
    "                'has_image': False,\n",
    "                'num_repetitions': n,\n",
    "                'correct_count': correct_count,\n",
    "                'accuracy': accuracy,\n",
    "                'ci_lower': ci_lower,\n",
    "                'ci_upper': ci_upper\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(aggregated)\n",
    "\n",
    "# ==== MAIN EXECUTION ====\n",
    "\n",
    "# Configuration\n",
    "NUM_REPETITIONS = 1  # Change this to desired number of repetitions\n",
    "FAKE_IMAGE_PATH = \"../data/Fake_Image_path/image.png\"\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting analysis with Google {MODEL_NAME}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Load your Excel data\n",
    "df = pd.read_excel(\"../data/subset_with_images.xlsx\", sheet_name=\"SSM_Q_ITA\")\n",
    "picture_link_col = df.columns.get_loc('picture_link') + 1\n",
    "workbook = openpyxl.load_workbook(\"../data/subset_with_images.xlsx\")\n",
    "worksheet = workbook[\"SSM_Q_ITA\"]\n",
    "\n",
    "# Estimate time\n",
    "num_questions = len(df)\n",
    "questions_with_images = df['picture_link'].notna().sum()\n",
    "questions_without_images = num_questions - questions_with_images\n",
    "\n",
    "# Time calculation\n",
    "# Questions with images: 2 API calls each (real + fake)\n",
    "# Questions without images: 1 API call each\n",
    "total_api_calls = (questions_with_images * 2 + questions_without_images) * NUM_REPETITIONS\n",
    "estimated_time_seconds = total_api_calls * DELAY_BETWEEN_REQUESTS\n",
    "estimated_time_minutes = estimated_time_seconds / 60\n",
    "estimated_time_hours = estimated_time_minutes / 60\n",
    "\n",
    "print(f\"ðŸ“Š Analysis Configuration:\")\n",
    "print(f\"   Total questions: {num_questions}\")\n",
    "print(f\"   Questions with images: {questions_with_images}\")\n",
    "print(f\"   Questions without images: {questions_without_images}\")\n",
    "print(f\"   Repetitions: {NUM_REPETITIONS}\")\n",
    "print(f\"   Delay between requests: {DELAY_BETWEEN_REQUESTS}s\")\n",
    "print(f\"\\nâ±ï¸  Estimated Time:\")\n",
    "print(f\"   Total API calls: {total_api_calls}\")\n",
    "print(f\"   Minimum time (with delays): {estimated_time_minutes:.1f} minutes ({estimated_time_hours:.1f} hours)\")\n",
    "print(f\"\\nðŸ’¡ Tip: Reduce DELAY_BETWEEN_REQUESTS if you have higher rate limits\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Store all results across repetitions\n",
    "all_results = []\n",
    "all_skipped = []\n",
    "\n",
    "# Run multiple repetitions\n",
    "for rep in range(1, NUM_REPETITIONS + 1):\n",
    "    results, skipped = process_single_repetition(\n",
    "        df, worksheet, picture_link_col, FAKE_IMAGE_PATH, rep\n",
    "    )\n",
    "    all_results.extend(results)\n",
    "    all_skipped.extend(skipped)\n",
    "\n",
    "DATETIME = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Save individual repetition results\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "all_results_df.to_csv(f\"results/gemini_{MODEL_NAME}_all_repetitions_detailed_{DATETIME}.csv\", index=False)\n",
    "print(f\"\\nâœ“ Saved all repetitions to results/gemini_{MODEL_NAME}_all_repetitions_detailed_{DATETIME}.csv\")\n",
    "\n",
    "# Compute and save aggregated statistics\n",
    "aggregated_df = compute_aggregated_statistics(all_results)\n",
    "aggregated_df.to_csv(f\"results/gemini_{MODEL_NAME}_aggregated_statistics_{DATETIME}.csv\", index=False)\n",
    "print(f\"âœ“ Saved aggregated statistics to results/gemini_{MODEL_NAME}_aggregated_statistics_{DATETIME}.csv\")\n",
    "\n",
    "# Save skipped questions\n",
    "if all_skipped:\n",
    "    skipped_df = pd.DataFrame(all_skipped)\n",
    "    skipped_df.to_csv(f\"results/gemini_{MODEL_NAME}_skipped_questions_{DATETIME}.csv\", index=False)\n",
    "    print(f\"âœ“ Saved skipped questions to results/gemini_{MODEL_NAME}_skipped_questions_{DATETIME}.csv\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"=== OVERALL SUMMARY for {MODEL_NAME} (across {NUM_REPETITIONS} repetitions) ===\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "total_questions = len(aggregated_df)\n",
    "questions_with_images = len(aggregated_df[aggregated_df['has_image'] == True])\n",
    "questions_without_images = total_questions - questions_with_images\n",
    "\n",
    "print(f\"\\nTotal unique questions: {total_questions}\")\n",
    "print(f\"Questions with images: {questions_with_images}\")\n",
    "print(f\"Questions without images: {questions_without_images}\")\n",
    "print(f\"Total evaluations: {len(all_results)}\")\n",
    "\n",
    "if questions_with_images > 0:\n",
    "    img_df = aggregated_df[aggregated_df['has_image'] == True]\n",
    "    \n",
    "    avg_real_accuracy = img_df['real_accuracy'].mean() * 100\n",
    "    avg_fake_accuracy = img_df['fake_accuracy'].mean() * 100\n",
    "    std_real_accuracy = img_df['real_accuracy'].std() * 100\n",
    "    std_fake_accuracy = img_df['fake_accuracy'].std() * 100\n",
    "    \n",
    "    # Overall confidence interval using all data points\n",
    "    total_real_correct = img_df['real_correct_count'].sum()\n",
    "    total_real_trials = img_df['num_repetitions'].sum()\n",
    "    total_fake_correct = img_df['fake_correct_count'].sum()\n",
    "    total_fake_trials = img_df['num_repetitions'].sum()\n",
    "    \n",
    "    from scipy import stats\n",
    "    real_overall_ci = stats.binom.interval(0.95, total_real_trials, total_real_correct/total_real_trials)\n",
    "    fake_overall_ci = stats.binom.interval(0.95, total_fake_trials, total_fake_correct/total_fake_trials)\n",
    "    \n",
    "    print(f\"\\n--- REAL Images ---\")\n",
    "    print(f\"Overall accuracy: {avg_real_accuracy:.1f}% Â± {std_real_accuracy:.1f}%\")\n",
    "    print(f\"95% CI: [{real_overall_ci[0]/total_real_trials*100:.1f}%, {real_overall_ci[1]/total_real_trials*100:.1f}%]\")\n",
    "    print(f\"Questions always correct: {len(img_df[img_df['real_accuracy'] == 1.0])}/{questions_with_images}\")\n",
    "    print(f\"Questions never correct: {len(img_df[img_df['real_accuracy'] == 0.0])}/{questions_with_images}\")\n",
    "    \n",
    "    print(f\"\\n--- FAKE Images ---\")\n",
    "    print(f\"Overall accuracy: {avg_fake_accuracy:.1f}% Â± {std_fake_accuracy:.1f}%\")\n",
    "    print(f\"95% CI: [{fake_overall_ci[0]/total_fake_trials*100:.1f}%, {fake_overall_ci[1]/total_fake_trials*100:.1f}%]\")\n",
    "    print(f\"Questions always correct: {len(img_df[img_df['fake_accuracy'] == 1.0])}/{questions_with_images}\")\n",
    "    print(f\"Questions never correct: {len(img_df[img_df['fake_accuracy'] == 0.0])}/{questions_with_images}\")\n",
    "\n",
    "if questions_without_images > 0:\n",
    "    no_img_df = aggregated_df[aggregated_df['has_image'] == False]\n",
    "    \n",
    "    avg_accuracy = no_img_df['accuracy'].mean() * 100\n",
    "    std_accuracy = no_img_df['accuracy'].std() * 100\n",
    "    \n",
    "    # Overall confidence interval\n",
    "    total_correct = no_img_df['correct_count'].sum()\n",
    "    total_trials = no_img_df['num_repetitions'].sum()\n",
    "    \n",
    "    from scipy import stats\n",
    "    overall_ci = stats.binom.interval(0.95, total_trials, total_correct/total_trials)\n",
    "    \n",
    "    print(f\"\\n--- WITHOUT Images ---\")\n",
    "    print(f\"Overall accuracy: {avg_accuracy:.1f}% Â± {std_accuracy:.1f}%\")\n",
    "    print(f\"95% CI: [{overall_ci[0]/total_trials*100:.1f}%, {overall_ci[1]/total_trials*100:.1f}%]\")\n",
    "    print(f\"Questions always correct: {len(no_img_df[no_img_df['accuracy'] == 1.0])}/{questions_without_images}\")\n",
    "    print(f\"Questions never correct: {len(no_img_df[no_img_df['accuracy'] == 0.0])}/{questions_without_images}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Analysis complete!\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e30d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20251107_201426'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATETIME = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "DATETIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb238ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "wandb 0.15.12 requires protobuf!=4.21.0,<5,>=3.19.0; sys_platform != \"linux\", but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Obtaining dependency information for google.generativeai from https://files.pythonhosted.org/packages/6e/40/c42ff9ded9f09ec9392879a8e6538a00b2dc185e834a3392917626255419/google_generativeai-0.8.5-py3-none-any.whl.metadata\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google.generativeai)\n",
      "  Obtaining dependency information for google-ai-generativelanguage==0.6.15 from https://files.pythonhosted.org/packages/7c/a3/67b8a6ff5001a1d8864922f2d6488dc2a14367ceb651bc3f09a947f2f306/google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Obtaining dependency information for google-api-core from https://files.pythonhosted.org/packages/ed/d4/90197b416cb61cefd316964fd9e7bd8324bcbafabf40eef14a9f20b81974/google_api_core-2.28.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Obtaining dependency information for google-api-python-client from https://files.pythonhosted.org/packages/96/58/c1e716be1b055b504d80db2c8413f6c6a890a6ae218a65f178b63bc30356/google_api_python_client-2.187.0-py3-none-any.whl.metadata\n",
      "  Downloading google_api_python_client-2.187.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Obtaining dependency information for google-auth>=2.15.0 from https://files.pythonhosted.org/packages/6f/d1/385110a9ae86d91cc14c5282c61fe9f4dc41c0b9f7d423c6ad77038c4448/google_auth-2.43.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from google.generativeai) (4.25.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from google.generativeai) (1.10.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from google.generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from google.generativeai) (4.15.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.3 from https://files.pythonhosted.org/packages/4e/6d/280c4c2ce28b1593a19ad5239c8b826871fc6ec275c21afc8e1820108039/proto_plus-1.26.1-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Obtaining dependency information for cachetools<7.0,>=2.0.0 from https://files.pythonhosted.org/packages/96/c5/1e741d26306c42e2bf6ab740b2202872727e0f606033c9dd713f8b93f5a8/cachetools-6.2.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl.metadata\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.0,>=1.56.2 from https://files.pythonhosted.org/packages/25/e8/eba9fece11d57a71e3e22ea672742c8f3cf23b35730c9e96db768b295216/googleapis_common_protos-1.71.0-py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.71.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (2.31.0)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Obtaining dependency information for httplib2<1.0.0,>=0.19.0 from https://files.pythonhosted.org/packages/8c/a2/0d269db0f6163be503775dc8b6a6fa15820cc9fdc866f6ba608d86b721f2/httplib2-0.31.0-py3-none-any.whl.metadata\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Obtaining dependency information for google-auth-httplib2<1.0.0,>=0.2.0 from https://files.pythonhosted.org/packages/44/a7/ca23dd006255f70e2bc469d3f9f0c82ea455335bfd682ad4d677adc435de/google_auth_httplib2-0.2.1-py3-none-any.whl.metadata\n",
      "  Downloading google_auth_httplib2-0.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Obtaining dependency information for uritemplate<5,>=3.0.1 from https://files.pythonhosted.org/packages/a9/99/3ae339466c9183ea5b8ae87b34c0b897eda475d2aec2307cae60e5cd4f29/uritemplate-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core->google.generativeai)\n",
      "  Obtaining dependency information for grpcio<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/60/9c/5c359c8d4c9176cfa3c61ecd4efe5affe1f38d9bae81e81ac7186b4c9cc8/grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core->google.generativeai)\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/8c/cc/27ba60ad5a5f2067963e6a858743500df408eb5855e98be778eaef8c9b02/grpcio_status-1.76.0-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zilef\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2023.7.22)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/d8/ad/6f414bb0b36eee20d93af6907256f208ffcda992ae6d3d7b6a778afe31e6/grpcio_status-1.75.1-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/2b/24/d536f0a0fda3a3eeb334893e5fb9d567c2777de6a5384413f71b35cfd0e5/grpcio_status-1.75.0-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/28/aa/1b1fe7d8ab699e1ec26d3a36b91d3df9f83a30abc07d4c881d0296b17b67/grpcio_status-1.74.0-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/2e/50/ee32e6073e2c3a4457be168e2bbf84d02ad9d2c18c4a578a641480c293d4/grpcio_status-1.73.1-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/e2/95/e4b963a8730e04fae0e98cdd12212a9ffb318daf8687ea3220b78b34f8fa/grpcio_status-1.73.0-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/14/53/473ee4db326aced076c5a7b503692cab10e3d0d963ac8916fc3a1994bc8a/grpcio_status-1.72.2-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/11/62/529a3d6b00792ef464d929ffa8980a300ad3030842880d04213ef9e6e0fd/grpcio_status-1.72.1-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for grpcio-status<2.0.0,>=1.33.2 from https://files.pythonhosted.org/packages/67/58/317b0134129b556a93a3b0afe00ee675b5657f0155509e22fcb853bafe2d/grpcio_status-1.71.2-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/81/7f/73cefb093e1a2a7c3ffd839e6f9fcafb7a427d300c7f8aef9c64405d8ac6/protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "   ---------------------------------------- 0.0/155.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 155.4/155.4 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.3/1.3 MB 42.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 20.9 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "   ---------------------------------------- 0.0/223.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 223.1/223.1 kB 13.3 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "   ---------------------------------------- 0.0/173.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 173.7/173.7 kB ? eta 0:00:00\n",
      "Downloading google_api_python_client-2.187.0-py3-none-any.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/14.6 MB 67.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.6/14.6 MB 58.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.3/14.6 MB 58.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.6 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading google_auth_httplib2-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 294.6/294.6 kB ? eta 0:00:00\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 91.1/91.1 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB ? eta 0:00:00\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.3/4.7 MB 74.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.7/4.7 MB 75.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 60.2 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 434.8/434.8 kB 26.5 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, cachetools, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.0\n",
      "    Uninstalling protobuf-4.25.0:\n",
      "      Successfully uninstalled protobuf-4.25.0\n",
      "Successfully installed cachetools-6.2.1 google-ai-generativelanguage-0.6.15 google-api-core-2.28.1 google-api-python-client-2.187.0 google-auth-2.43.0 google-auth-httplib2-0.2.1 google.generativeai-0.8.5 googleapis-common-protos-1.71.0 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 rsa-4.9.1 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google.generativeai "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
